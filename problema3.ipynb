{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/david/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/david/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     /Users/david/nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from es-core-news-sm==3.7.0) (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/david/.local/share/virtualenvs/Algebra_Taller3_Camilo_David-iO2jm3hJ/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('snowball_data')\n",
    "spacy.cli.download('es_core_news_sm')\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spanish_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_spanish_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        input_text = f.read()\n",
    "    matches = re.finditer(r\"-={Concordancia}=-\\n(.*?)\\n-={Referencia bibliográfica}=-\", input_text, re.DOTALL)\n",
    "    extracted_texts = []\n",
    "    for match in matches:\n",
    "        extracted_text = match.group(1).strip()\n",
    "        extracted_texts.append(extracted_text)\n",
    "    return extracted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = []\n",
    "all_texts = [*all_texts, *extract_texts('economia.txt')]\n",
    "all_texts = [*all_texts, *extract_texts('politica.txt')]\n",
    "all_texts = [*all_texts, *extract_texts('medicina.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todos sus elementos, así los llamados \"espirituales\" como los que se dicen \"materiales\", pues unos y otros, pese a esa convencional dicotomía, no son sino hechos igualmente humanos, interdependientes e integrantes de la plenitud de esa cultura. No solamente el folklore, sino las artes literarias y plásticas, así como la economía, el derecho, la magia y todos los demás hechos humanos de cualquier pueblo o época son igualmente objeto de la ciencia antropológica, especialmente de la etnografía. El estudio de un canto tiene tanto valor, o más valor, que el de un ángulo facial, las mudanzas de un baile no significan menos que la\n"
     ]
    }
   ],
   "source": [
    "print(all_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todos sus elementos, así los llamados \"espirit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Del consumo económico de tales areítos puede d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No puede negarse que en tales funciones había ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cuando llevara al exceso. Hubiera sido ofender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En todo tiempo ha existido el alarde de riquez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>. Había 15 veces menos estudiantes de este tip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>La situación nacional de la enseñanza de cienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>nacional de la enseñanza de ciencias de la sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>A este respecto pueden mencionarse dos indicad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>Esto puede dar una idea no sólo de las defecci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     todos sus elementos, así los llamados \"espirit...\n",
       "1     Del consumo económico de tales areítos puede d...\n",
       "2     No puede negarse que en tales funciones había ...\n",
       "3     cuando llevara al exceso. Hubiera sido ofender...\n",
       "4     En todo tiempo ha existido el alarde de riquez...\n",
       "...                                                 ...\n",
       "2998  . Había 15 veces menos estudiantes de este tip...\n",
       "2999  La situación nacional de la enseñanza de cienc...\n",
       "3000  nacional de la enseñanza de ciencias de la sal...\n",
       "3001  A este respecto pueden mencionarse dos indicad...\n",
       "3002  Esto puede dar una idea no sólo de las defecci...\n",
       "\n",
       "[3003 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_texts, columns=['text'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(remove_spanish_stopwords)\n",
    "df['text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elemento , así llamado \" espiritual \" decir \" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consumo económico tal areíto poder decir él an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poder negar él tal función considerable derroc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llevar exceso . ser ofender canon buen gusto s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tiempo existir alarde riqueza trascendente \" f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>. 15 vez menos estudiante tipo medicina número...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>situación nacional enseñanzar ciencia salud , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>nacional enseñanzar ciencia salud , punto vist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>respecto poder mencionar él dos indicador ilus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>poder dar idea sólo defección causa económico-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     elemento , así llamado \" espiritual \" decir \" ...\n",
       "1     consumo económico tal areíto poder decir él an...\n",
       "2     poder negar él tal función considerable derroc...\n",
       "3     llevar exceso . ser ofender canon buen gusto s...\n",
       "4     tiempo existir alarde riqueza trascendente \" f...\n",
       "...                                                 ...\n",
       "2998  . 15 vez menos estudiante tipo medicina número...\n",
       "2999  situación nacional enseñanzar ciencia salud , ...\n",
       "3000  nacional enseñanzar ciencia salud , punto vist...\n",
       "3001  respecto poder mencionar él dos indicador ilus...\n",
       "3002  poder dar idea sólo defección causa económico-...\n",
       "\n",
       "[3003 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3003, 16764)\n",
      "16764\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "vectors_tfidf = vectorizer_tfidf.fit_transform(df['text']).todense()\n",
    "vocab = np.array(vectorizer_tfidf.get_feature_names_out())\n",
    "print(vectors_tfidf.shape)\n",
    "print(len(vocab))\n",
    "print(vectors_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 1\n",
    "d = 3\n",
    "\n",
    "def show_topics(vocab, H):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in H])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = decomposition.NMF(n_components=d)\n",
    "\n",
    "W = nmf.fit_transform(np.asarray(vectors_tfidf))\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3003, 3)\n",
      "(3, 16764)\n",
      "[[0.00058605 0.00100175 0.00128326 ... 0.07997246 0.01176431 0.00215774]\n",
      " [0.00172045 0.         0.         ... 0.00363879 0.00187594 0.00048085]\n",
      " [0.         0.         0.         ... 0.03153298 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(W.shape)\n",
    "print(H.shape)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medicina', 'economía', 'político']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(vocab, H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algebra_Taller3_Camilo_David-iO2jm3hJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
